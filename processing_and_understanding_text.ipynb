{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Extracting text data by using web scraping\nimport requests\nfrom bs4 import BeautifulSoup\n\nheaders = {\n    \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n    AppleWebKit/537.36(KHTML, like Gecko) Chrome/110.0.5481.178 Safari/537.36\"\n}\nurl=\"https://www.hsph.harvard.edu/nutritionsource/what-should-you-eat/whole-grains/\"\n\npage = requests.get(url, headers=headers)\nsoup = BeautifulSoup(page.content, \"html.parser\")\ntitle = soup.title.get_text().strip()\n\nparagraphs=[]\nfor para in soup.find_all(\"p\"):\n    paragraph = para.get_text()\n    paragraphs += [paragraph]\n    \nbody = str(\"\\n\\n\".join(paragraphs))\ntext = title + \"\\n\\n\" + body","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting text into sentences and words, pos tagging using NLTK\nimport nltk\nfrom nltk import sent_tokenize, word_tokenize, pos_tag\n\nsent_list = sent_tokenize(text)\nword_list = word_tokenize(text)\npos = pos_tag(word_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stemming\nfrom nltk.stem import SnowballStemmer\n\nss = SnowballStemmer(\"english\")\nstem = [ss.stem(word) for word in word_list]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import wordnet as wn\nnltk.download('omw-1.4')\nnltk.download('wordnet2022')\n! cp -rf /usr/share/nltk_data/corpora/wordnet2022 /usr/share/nltk_data/corpora/wordnet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lemmatization\nfrom nltk.stem import WordNetLemmatizer\n\nwn = WordNetLemmatizer()\nlem = wn.lemmatize(\"experiences\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Contraction\n!pip install contractions\nimport contractions\n\nsentence = \"She didn't tell me the story\"\ncon = contractions.fix(sentence)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correct spelling\n!pip install autocorrect\nfrom autocorrect import Speller\n\nspell = Speller()\ntext = \"hte car is luxury\"\ncorr = spell(text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove stopwords\nfrom nltk.corpus import stopwords\n\nstop_words = set(stopwords.words(\"english\"))\nremove_stopwords = []\nfor word in word_list:\n    if word not in stop_words:\n        remove_stopwords.append(word)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}